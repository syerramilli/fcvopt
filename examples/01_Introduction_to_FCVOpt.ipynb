{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to FCVOpt \n",
    "\n",
    "This notebook demonstrates the FCVOpt API for efficient hyperparameter optimization using **fractional cross-validation**. We'll tune a Random Forest classifier on a synthetic dataset to illustrate the key concepts and workflow.\n",
    "\n",
    "## What is FCVOpt?\n",
    "\n",
    "FCVOpt implements an innovative approach to hyperparameter optimization that addresses a fundamental challenge in machine learning:\n",
    "\n",
    "- **The Problem**: K-fold cross-validation is more robust than simple train-test splits, but requires fitting K models at each hyperparameter configuration—making optimization computationally expensive.\n",
    "  \n",
    "- **The Solution**: FCVOpt uses a hierarchical Gaussian process model to exploit correlation between folds across the hyperparameter space. This allows the algorithm to evaluate only one CV fold for many configurations while still providing reliable estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "from fcvopt.optimizers import FCVOpt\n",
    "from fcvopt.crossvalidation import SklearnCVObj\n",
    "from fcvopt.configspace import ConfigurationSpace\n",
    "from ConfigSpace import Integer, Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "\n",
    "We'll create a synthetic binary classification dataset with the following characteristics:\n",
    "- 1,250 samples with 50 features\n",
    "- Only 10 features are informative, 25 are redundant, and the rest are noise\n",
    "- 10% label noise to make the problem more realistic\n",
    "- 80/20 train/test split for final model evaluation\n",
    "\n",
    "**Note**: The test set is held out entirely and will only be used to evaluate the final optimized model. It plays no role in hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1000 samples, 50 features\n",
      "Test set: 250 samples\n",
      "Class distribution: [497 503]\n"
     ]
    }
   ],
   "source": [
    "# Generate sample classification data\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, \n",
    "    n_features=50, \n",
    "    n_informative=10,\n",
    "    n_redundant=25,\n",
    "    n_classes=2,\n",
    "    flip_y=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCVOPT API\n",
    "\n",
    "FCVOpt follows a simple and intuitive three-step process:\n",
    "\n",
    "```\n",
    "1. Define Cross-Validation Objective\n",
    "   ↓\n",
    "2. Define Hyperparameter Search Space  \n",
    "   ↓\n",
    "3. Run Optimization\n",
    "```\n",
    "Let's walk through each step in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1: Define the Cross-Validation Objective\n",
    "The CV objective encapsulates:\n",
    "- **What model** we're optimizing (RandomForestClassifier)\n",
    "- **What data** we're using (X_train, y_train)\n",
    "- **What metric** we're minimizing (misclassification rate)\n",
    "- **How many folds** to use (10-fold CV)\n",
    "\n",
    "For scikit-learn estimators, FCVOpt provides the convenient `SklearnCVObj` wrapper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CV objective with 10 folds\n"
     ]
    }
   ],
   "source": [
    "# Create CV objective for Random Forest\n",
    "cv_obj = SklearnCVObj(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    X=X_train, \n",
    "    y=y_train,\n",
    "    loss_metric=zero_one_loss,  # Minimize misclassification rate\n",
    "    task='binary-classification',\n",
    "    n_splits=10,  # 5-fold cross-validation\n",
    "    rng_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Created CV objective with {cv_obj.cv.get_n_splits()} folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the hyperparameter search space\n",
    "\n",
    "The configuration space specifies which hyperparameters to optimize and their valid ranges. For Random Forest, we'll tune:\n",
    "\n",
    "| Hyperparameter | Range | Scale | Description |\n",
    "|----------------|-------|-------|-------------|\n",
    "| `n_estimators` | [50, 1000] | Log | Number of trees in the forest |\n",
    "| `max_depth` | [1, 15] | Log | Maximum depth of each tree |\n",
    "| `max_features` | [0.01, 1.0] | Log | Fraction of features to consider for splits |\n",
    "| `min_samples_split` | [2, 200] | Log | Minimum samples required to split a node |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    max_depth, Type: UniformInteger, Range: [1, 15], Default: 4, on log-scale\n",
      "    max_features, Type: UniformFloat, Range: [0.01, 1.0], Default: 0.1, on log-scale\n",
      "    min_samples_split, Type: UniformInteger, Range: [2, 200], Default: 20, on log-scale\n",
      "    n_estimators, Type: UniformInteger, Range: [50, 1000], Default: 224, on log-scale\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "config = ConfigurationSpace()\n",
    "config.add([\n",
    "    Integer('n_estimators', bounds=(50, 1000), log=True),\n",
    "    Integer('max_depth', bounds=(1, 15), log=True),\n",
    "    Float('max_features', bounds=(0.01, 1.0), log=True),\n",
    "    Integer('min_samples_split', bounds=(2, 200), log=True)\n",
    "])\n",
    "config.generate_indices()\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize and Run the Optimizer\n",
    "\n",
    "Now we're ready to optimize! Key parameters for `FCVOpt`:\n",
    "\n",
    "- `obj`: The objective function to minimize (CV loss)\n",
    "- `n_folds`: Number of CV folds in the objective\n",
    "- `config`: The search space we defined\n",
    "- `acq_function`: Acquisition function for Bayesian optimization\n",
    "  - `'LCB'` (Lower Confidence Bound): Faster, good for exploration/exploitation balance\n",
    "  - `'KG'` (Knowledge Gradient): Often better results but slower\n",
    "- `tracking_dir`: Directory for MLflow experiment tracking\n",
    "- `experiment`: Name for this optimization run\n",
    "\n",
    "We'll run 25 trials, which means evaluating 25 different hyperparameter configurations, each evaluated on a single held-out fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/22 21:54:59 INFO mlflow.tracking.fluent: Experiment with name 'rf_tuning_example' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of candidates evaluated.....: 25\n",
      "Observed obj at incumbent..........: 0.09\n",
      "Estimated obj at incumbent.........: 0.0996302\n",
      "\n",
      " Best Configuration at termination:\n",
      " Configuration(values={\n",
      "  'max_depth': 15,\n",
      "  'max_features': 0.1314003108823,\n",
      "  'min_samples_split': 5,\n",
      "  'n_estimators': 1000,\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Initialize FCVOpt optimizer\n",
    "optimizer = FCVOpt(\n",
    "    obj=cv_obj.cvloss,\n",
    "    n_folds=cv_obj.cv.get_n_splits(),\n",
    "    config=config,\n",
    "    acq_function='LCB',  # Lower Confidence Bound acquisition\n",
    "    tracking_dir='./hp_opt_runs/',  # MLflow tracking directory\n",
    "    experiment='rf_tuning_example',\n",
    ")\n",
    "\n",
    "# run for 25 trials \n",
    "best_conf = optimizer.optimize(n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Final Model\n",
    "\n",
    "Now we train a Random Forest with the optimized hyperparameters on the full training set and evaluate it on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, max_features=0.1314003108823,\n",
       "                       min_samples_split=5, n_estimators=1000,\n",
       "                       random_state=1382689815)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, max_features=0.1314003108823,\n",
       "                       min_samples_split=5, n_estimators=1000,\n",
       "                       random_state=1382689815)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, max_features=0.1314003108823,\n",
       "                       min_samples_split=5, n_estimators=1000,\n",
       "                       random_state=1382689815)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the model with best hyperparmeters found\n",
    "best_model = cv_obj.construct_model(dict(best_conf))\n",
    "\n",
    "# train the model on the data\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance:\n",
      "  Training Misclassification Rate....:0.0020\n",
      "  Test Misclassification Rate.......: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_mcr = zero_one_loss(y_train, y_train_pred)\n",
    "test_mcr = zero_one_loss(y_test, y_test_pred)\n",
    "\n",
    "print(\"Final Model Performance:\")\n",
    "print(f\"  Training Misclassification Rate....:{train_mcr:.4f}\")\n",
    "print(f\"  Test Misclassification Rate.......: {test_mcr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcvopt_test",
   "language": "python",
   "name": "fcvopt_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
