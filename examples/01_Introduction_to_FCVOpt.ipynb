{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to FCVOpt \n",
    "\n",
    "This notebook demonstrates the FCVOpt API for efficient hyperparameter optimization using **fractional cross-validation**. We'll tune a Random Forest classifier on a synthetic dataset to illustrate the key concepts and workflow.\n",
    "\n",
    "## What is FCVOpt?\n",
    "\n",
    "FCVOpt implements an innovative approach to hyperparameter optimization that addresses a fundamental challenge in machine learning:\n",
    "\n",
    "- **The Problem**: K-fold cross-validation is more robust than simple train-test splits, but requires fitting K models at each hyperparameter configuration—making optimization computationally expensive.\n",
    "  \n",
    "- **The Solution**: FCVOpt uses a hierarchical Gaussian process model to exploit correlation between folds across the hyperparameter space. This allows the algorithm to evaluate only one CV fold for many configurations while still providing reliable estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "from fcvopt.optimizers import FCVOpt\n",
    "from fcvopt.crossvalidation import SklearnCVObj\n",
    "from fcvopt.configspace import ConfigurationSpace\n",
    "from ConfigSpace import Integer, Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "\n",
    "We create a synthetic binary classification dataset for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features matrix: (1250, 50)\n",
      "Class distribution: [621 629]\n"
     ]
    }
   ],
   "source": [
    "# Generate sample classification data\n",
    "X, y = make_classification(\n",
    "    n_samples=1250, \n",
    "    n_features=50, \n",
    "    n_informative=10,\n",
    "    n_redundant=25,\n",
    "    n_classes=2,\n",
    "    flip_y=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Shape of features matrix: {X.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCVOPT API\n",
    "\n",
    "FCVOpt follows a simple and intuitive three-step process:\n",
    "\n",
    "```\n",
    "1. Define Cross-Validation Objective\n",
    "   ↓\n",
    "2. Define Hyperparameter Search Space  \n",
    "   ↓\n",
    "3. Run Optimization\n",
    "```\n",
    "Let's walk through each step in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1: Define the Cross-Validation Objective\n",
    "The CV objective encapsulates:\n",
    "- **What model** we're optimizing (RandomForestClassifier)\n",
    "- **What data** we're using (X, y)\n",
    "- **What metric** we're minimizing (misclassification rate)\n",
    "- **How many folds** to use (10-fold CV)\n",
    "\n",
    "For scikit-learn estimators, FCVOpt provides the convenient `SklearnCVObj` wrapper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CV objective with 10 folds\n"
     ]
    }
   ],
   "source": [
    "# Create CV objective for Random Forest\n",
    "cv_obj = SklearnCVObj(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    X=X, y=y,\n",
    "    loss_metric=zero_one_loss,  # Minimize misclassification rate\n",
    "    task='classification',\n",
    "    n_splits=10, \n",
    "    rng_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Created CV objective with {cv_obj.cv.get_n_splits()} folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the hyperparameter search space\n",
    "\n",
    "The configuration space specifies which hyperparameters to optimize and their valid ranges. For Random Forest, we'll tune:\n",
    "\n",
    "| Hyperparameter | Range | Scale | Description |\n",
    "|----------------|-------|-------|-------------|\n",
    "| `n_estimators` | [50, 1000] | Log | Number of trees in the forest |\n",
    "| `max_depth` | [1, 15] | Log | Maximum depth of each tree |\n",
    "| `max_features` | [0.01, 1.0] | Log | Fraction of features to consider for splits |\n",
    "| `min_samples_split` | [2, 200] | Log | Minimum samples required to split a node |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    max_depth, Type: UniformInteger, Range: [1, 15], Default: 4, on log-scale\n",
      "    max_features, Type: UniformFloat, Range: [0.01, 1.0], Default: 0.1, on log-scale\n",
      "    min_samples_split, Type: UniformInteger, Range: [2, 200], Default: 20, on log-scale\n",
      "    n_estimators, Type: UniformInteger, Range: [50, 1000], Default: 224, on log-scale\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "config = ConfigurationSpace()\n",
    "config.add([\n",
    "    Integer('n_estimators', bounds=(50, 1000), log=True),\n",
    "    Integer('max_depth', bounds=(1, 15), log=True),\n",
    "    Float('max_features', bounds=(0.01, 1.0), log=True),\n",
    "    Integer('min_samples_split', bounds=(2, 200), log=True)\n",
    "])\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize and Run the Optimizer\n",
    "\n",
    "Now we're ready to optimize! Key parameters for `FCVOpt`:\n",
    "\n",
    "- `obj`: The objective function to minimize (CV loss)\n",
    "- `n_folds`: Number of CV folds in the objective\n",
    "- `config`: The search space we defined\n",
    "- `acq_function`: Acquisition function for Bayesian optimization\n",
    "  - `'LCB'` (Lower Confidence Bound): Faster, good for exploration/exploitation balance\n",
    "  - `'KG'` (Knowledge Gradient): Often better results but slower\n",
    "- `tracking_dir`: Directory for MLflow experiment tracking\n",
    "- `experiment`: Name for this optimization run\n",
    "\n",
    "We'll run 50 trials, which means evaluating 50 different hyperparameter configurations, each evaluated on a single held-out fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of candidates evaluated.....: 50\n",
      "Observed obj at incumbent..........: 0.088\n",
      "Estimated obj at incumbent.........: 0.0802439\n",
      "\n",
      " Best Configuration at termination:\n",
      " Configuration(values={\n",
      "  'max_depth': 15,\n",
      "  'max_features': 0.0693042025806,\n",
      "  'min_samples_split': 2,\n",
      "  'n_estimators': 1000,\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Initialize FCVOpt optimizer\n",
    "optimizer = FCVOpt(\n",
    "    obj=cv_obj.cvloss,\n",
    "    n_folds=cv_obj.cv.get_n_splits(),\n",
    "    config=config,\n",
    "    acq_function='LCB',  # Lower Confidence Bound acquisition\n",
    "    tracking_dir='./hp_opt_runs/',  # MLflow tracking directory\n",
    "    experiment='rf_tuning_example',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# run for 50 trials \n",
    "best_conf = optimizer.optimize(n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10-fold CV Misclassification Rate....:0.084000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best configuration\n",
    "best_cv_mcr = cv_obj(best_conf)\n",
    "print(f\" 10-fold CV Misclassification Rate....:{best_cv_mcr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model with best hyperparmeters found\n",
    "best_model = cv_obj.construct_model(dict(best_conf))\n",
    "\n",
    "# train the model on the data\n",
    "_ = best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcvopt_test",
   "language": "python",
   "name": "fcvopt_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
